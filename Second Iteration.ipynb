{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can establish our framework by defining the variables to be used.  We start with the outcome variable, $Y$.  Next, we consider out treatment variable, $A_k$, which takes on value 1 if there is treatment, and is 0 otherwise.  To begin, we will use treatment strategies that are exclusively treatment or exclusively no treatment, corresponding to $\\overline{a} = (1,1,\\dots,1) = \\overline{1}$ and $\\overline{a} = (0,0,\\dots,0) = \\overline{0}$ respectively.  The next measurable variable is $L$, which represents the covariate(s) to be included.  Note that both the covariates, $L$, and the outcome, $Y$ are affected by an unmeasured common cause, $U$.  The diagram below illustrates these relationships.  \n",
    "\n",
    "![title](image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Creation\n",
    "\n",
    "We first need to simulate the data. We will build out the covariates of the population.  For simplicity, we will use one binary covariate, $L_1$.  \n",
    "\n",
    "The data is being simulated using the following equations, where U is an underlying confounder.  \n",
    "\n",
    "$$logitP[L_k] = \\alpha_0 + \\alpha_1 \\cdot L_{k-1} + \\alpha_2 \\cdot L_{k-2} + \\alpha_3 A_{k-1} + \\alpha_4 A_{K-2} + \\alpha_5 U$$ \n",
    "\n",
    "\n",
    "$$ logit[A_k] = \\beta_0 + \\beta_1 L_{k} + \\beta_2 L_{k-1} + \\beta_3 A_{k-1} + \\beta_4 A_{K-2} $$ \n",
    "\n",
    "Then, an end $Y$ value will be pulled from the following \n",
    "$$ Y \\sim N(\\mu = U, \\sigma = 1) $$ \n",
    "\n",
    "where $U \\sim Unif(0.1, 1)$ \n",
    "\n",
    "\n",
    "## G-formula Simulation Study \n",
    "\n",
    "The purpose of this investigation is to measure the average causal effect of treatment, which can be estimated using \n",
    "$$ \\mathbb{E}\\big[Y^{a=1}\\big] - \\mathbb{E}\\big[Y^{a=0}\\big]$$ \n",
    "for the respective $\\bar{a} = \\bar{0}$ and $\\bar{a} = \\bar{1}$\n",
    "\n",
    "We want to build out the g-formula as follows  \n",
    "$$ \\mathbb{E} \\big[Y^{\\overline{a}}\\big]  = \\sum_{l_i} \\mathbb{E} \\big[Y \\mid A_{0} = a_{0},  \\; A_{1} = a_{1}, \\cdots, \\; A_{t} = a_{t},  \\; L_{0} = l_0, \\; L_{1} = l_1, \\cdots, \\; L_{t} = l_t,\\big] \\prod_{k=0}^t P(L_k = l_k \\mid \\overline{L}_{k-1}, \\overline{A}_{k-1})  $$\n",
    "\n",
    "We can do this by building out two models, one for $Y$ And one for $L$.  We will begin by using a continous $Y$ and a binary $L$ for simplicity.  \n",
    "\n",
    "For $Y$, we will use a linear regression, and the model will look something like this \n",
    "\n",
    "$$\\mathbb{E} \\big[Y \\mid \\overline{A}_t, \\overline{L}_t \\big] = \\theta_{0} + \\theta_1 A_{t}+ \\theta_2 A_{t-1} + \\cdots + \\theta_j A_0 + \\theta_{j+1} L_t + \\theta_{j+2} L_{t-1} + \\cdots + \\theta_{j+k} L_0 $$ \n",
    "\n",
    "For each $L$, we will use a logistic regression, also calculated on a time delay of t=2.  This will give us something similar to \n",
    "\n",
    "$$ logit(L_k) = \\gamma_0 + \\gamma_1 L_{k-1} + \\gamma_2 L_{k-2} + \\gamma_3 A_{k-1} + \\gamma_4 A_{k-2} $$ \n",
    "\n",
    "For the treatment $A$, we will also use a logistic regression on a time delay of 2, similar to, \n",
    "$$ logit(A_k) = \\zeta_0 + \\zeta_1 L_{k} + \\zeta_2 L_{k-1} + \\zeta_3 A_{k-1} + \\zeta_4 A_{k-2} $$ \n",
    "\n",
    "\n",
    "\n",
    "Using these models, I simulated 1000 mean casual effects for 500 individual datasets.  \n",
    "<!---what quadratic time term needed to be added here? --->\n",
    "\n",
    "## Results \n",
    "Mean of means of differences: 1.7217286172967964e-07\n",
    "\n",
    "Variance of means of differences: 2.3894070465421745e-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import math\n",
    "import csv\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import random\n",
    "import time \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] data_creation simulates data for a given number of \n",
    "## individuals(indiv) over a set amount of time (max_time), and can \n",
    "## include as many covariates as desired (number_of_covariates)\n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def data_creation(indiv, max_time, number_of_covariates): \n",
    "\n",
    "    columns = [\"indiv\", \"time\",\"U\", \"A\", \"Y\",  \"L1\"]\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    coefficient_df = pd.DataFrame(columns = [\"indiv\", \"alpha_0\", \"alpha_1\", \\\n",
    "                     \"alpha_2\", \"alpha_3\", \"alpha_4\", \"alpha_5\", \"beta_0\", \\\n",
    "                     \"beta_1\", \"beta_2\", \"beta_3\", \"beta_4\"])\n",
    "\n",
    "    alpha_0 = np.random.uniform(low = -1, high = 1)\n",
    "    alpha_1 = np.random.uniform(low = -1, high = 1)\n",
    "    alpha_2 = np.random.uniform(low = -1, high = 1)\n",
    "    alpha_3 = np.random.uniform(low = -1, high = 1)        \n",
    "    alpha_4 = np.random.uniform(low = -1, high = 1)\n",
    "    alpha_5 = np.random.uniform(low = -1, high = 1)\n",
    "\n",
    "    beta_0 = np.random.uniform(low = -1, high = 1)\n",
    "    beta_1 = np.random.uniform(low = -1, high = 1)\n",
    "    beta_2 = np.random.uniform(low = -1, high = 1)\n",
    "    beta_3 = np.random.uniform(low = -1, high = 1)\n",
    "    beta_4 = np.random.uniform(low = -1, high = 1)\n",
    "    \n",
    "    for ii in range(1,indiv+1):\n",
    "\n",
    "        coefficient_df.loc[len(coefficient_df)+1] = [ii, alpha_0, alpha_1, alpha_2, \\\n",
    "                alpha_3, alpha_4, alpha_5, beta_0, beta_1, beta_2, beta_3, beta_4, ]\n",
    "     \n",
    "        ## creating an unobserved variable that affects covariates \n",
    "        U = np.random.uniform(low = 0.1, high = 1)\n",
    "            \n",
    "        for jj in range(0, max_time+1): \n",
    "            if jj == 0: \n",
    "                x_L = alpha_0 + alpha_5*U \n",
    "                L1 = np.random.binomial(n=1, p = np.exp(x_L)/(1+np.exp(x_L)))\n",
    "\n",
    "                x_A = beta_0 + beta_1*L1 \n",
    "                A = np.random.binomial(n=1, p = np.exp(x_A)/(1+np.exp(x_A)))\n",
    "\n",
    "                df.loc[len(df)+1] = [ii, jj, U, A, \"NaN\",  L1]\n",
    "\n",
    "            elif jj == 1: \n",
    "                x_L = alpha_0 + alpha_1*float(df[\"L1\"][(df.time == jj-1) & (df.indiv == ii)]) \\\n",
    "                    +alpha_3*float(df[\"A\"][(df.time == jj-1) & (df.indiv == ii)])+ alpha_5*U \n",
    "                \n",
    "                L1 = np.random.binomial(n=1, p = np.exp(x_L)/(1+np.exp(x_L)))\n",
    "\n",
    "                \n",
    "                x_A = beta_0 + beta_1*L1 + beta_2*float(df[\"L1\"][(df.time == jj-1) & (df.indiv == ii)])\\\n",
    "                    + beta_3*float(df[\"A\"][(df.time == jj-1) & (df.indiv == ii)])\n",
    "                \n",
    "                A = np.random.binomial(n=1, p = np.exp(x_A)/(1+np.exp(x_A)))\n",
    "\n",
    "                df.loc[len(df)+1] = [ii, jj, U, A, \"NaN\", L1]\n",
    "\n",
    "            else: \n",
    "                x_L = alpha_0 + alpha_1*float(df[\"L1\"][(df.time == jj-1) & (df.indiv == ii)])\\\n",
    "                    +alpha_2*float(df[\"L1\"][(df.time == jj-2) & (df.indiv == ii)])\\\n",
    "                    +alpha_3*float(df[\"A\"][(df.time == jj-1) & (df.indiv == ii)])\\\n",
    "                    +alpha_4*float(df[\"A\"][(df.time == jj-2) & (df.indiv == ii)])+ alpha_5*U \n",
    "                \n",
    "                L1 = np.random.binomial(n=1, p = np.exp(x_L)/(1+np.exp(x_L)))\n",
    "\n",
    "\n",
    "                x_A = beta_0 + beta_1*L1 + beta_2*float(df[\"L1\"][(df.time == jj-1) & (df.indiv == ii)])\\\n",
    "                    + beta_3*float(df[\"A\"][(df.time == jj-1) & (df.indiv == ii)])+ \\\n",
    "                    beta_4*float(df[\"A\"][(df.time == jj-2) & (df.indiv == ii)])\n",
    "                \n",
    "                A = np.random.binomial(n=1, p = np.exp(x_A)/(1+np.exp(x_A)))\n",
    "\n",
    "                if jj == max_time: \n",
    "                    # Y = np.random.normal(loc = U, scale = 1)\n",
    "                    x_Y = 0.5 + U \n",
    "                    Y = np.random.binomial(n=1, p = np.exp(x_Y)/(1+np.exp(x_Y)))\n",
    "                    df.loc[len(df)+1] = [ii, jj, U, A, Y, L1]\n",
    "\n",
    "                else: \n",
    "                    df.loc[len(df)+1] = [ii, jj, U, A, \"NaN\", L1]\n",
    "\n",
    "    # creating shifted values \n",
    "    # for kk in range(1,max_time+1):\n",
    "    for kk in range(1,4):\n",
    "        df[\"L1_\"+str(kk)] = df.L1.shift(kk)\n",
    "        df[\"A_\"+str(kk)] = df.A.shift(kk)\n",
    "\n",
    "    return(df, coefficient_df); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] Y_model_creation creates the linear regression model for \n",
    "## the observed Ys based on the treatments (A) and covariates (L)  \n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "## Creating model for Y \n",
    "\n",
    "def Y_model_creation(df, max_time): \n",
    "    temp_df = df[df.time == max_time]\n",
    "    train_columns ='+'.join(map(str, np.append(list(df)[3],list(df)[5:])))\n",
    "    temp_df = temp_df.astype(float)\n",
    "    Y_model = smf.ols(\"Y~\"+train_columns, data=temp_df).fit()\n",
    "    return(Y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] covariate_model_creation creates the logistic regression \n",
    "## for the observed covariate (L) data from the previous covariates \n",
    "## and the previous treatments (A) \n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def covariate_model_creation(df, max_time): \n",
    "    columns = [\"time\", \"gamma_0\", \"gamma_1\", \"gamma_2\", \"gamma_3\", \"gamma_4\"]\n",
    "    train_columns = [\"L1_1\", \"L1_2\", \"A_1\", \"A_2\"]\n",
    "    L1_model_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "    for ii in range(1, (max_time+1)): \n",
    "        temp_df = df[df.time == ii]   \n",
    "        if ii == 1: \n",
    "            L1_model = sm.Logit(np.asarray(temp_df[\"L1\"]), np.asarray(sm.add_constant(temp_df[[\"L1_1\", \"A_1\"]]))).fit()\n",
    "            L1_model_df = L1_model_df.append(pd.DataFrame([ii] + [L1_model.params[i] for i in range(0,2)] + [\"Nan\"] + [L1_model.params[2]] + [\"Nan\"], index = columns).transpose(), ignore_index=True)\n",
    "        else: \n",
    "            L1_model = sm.Logit(np.asarray(temp_df[\"L1\"]), np.asarray(sm.add_constant(temp_df[train_columns]))).fit()\n",
    "            L1_model_df = L1_model_df.append(pd.DataFrame([ii] + [L1_model.params[i] for i in range(0,5)], index = columns).transpose(), ignore_index=True)\n",
    "    return(L1_model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ logit(L_k) = \\gamma_0 + \\gamma_1 L_{k-1} + \\gamma_2 L_{k-2} + \\gamma_3 A_{k-1} + \\gamma_4 A_{k-2} $$ \n",
    "\n",
    "$$ logit(A_k) = \\zeta_0 + \\zeta_1 L_{k} + \\zeta_2 L_{k-1} + \\zeta_3 A_{k-1} + \\zeta_4 A_{k-2} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] treatment_model_creation creates the logistic regression \n",
    "## for the observed treatment (A) data from the current and previous \n",
    "## covariates and the previous treatments (A) \n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def treatment_model_creation(df, max_time): \n",
    "    columns = [\"time\", \"zeta_0\", \"zeta_1\", \"zeta_2\", \"zeta_3\", \"zeta_4\"]\n",
    "    train_columns = [\"L1\", \"L1_1\", \"A_1\", \"A_2\"]\n",
    "    A_model_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "    for ii in range(1, (max_time+1)): \n",
    "        temp_df = df[df.time == ii]   \n",
    "        if ii == 1: \n",
    "            A_model = sm.Logit(np.asarray(temp_df[\"A\"]), np.asarray(sm.add_constant(temp_df[[\"L1\", \"L1_1\", \"A_1\"]]))).fit()\n",
    "            A_model_df = A_model_df.append(pd.DataFrame([ii] + [A_model.params[i] for i in range(0,4)] + [\"Nan\"], index = columns).transpose(), ignore_index=True)\n",
    "        else: \n",
    "            A_model = sm.Logit(np.asarray(temp_df[\"A\"]), np.asarray(sm.add_constant(temp_df[train_columns]))).fit()\n",
    "            A_model_df = A_model_df.append(pd.DataFrame([ii] + [A_model.params[i] for i in range(0,5)], index = columns).transpose(), ignore_index=True)\n",
    "    return(A_model_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def s_model_creation(T, time_df): \n",
    "    train_columns = [\"L1_1\", \"L1_2\", \"A_1\", \"A_2\"]\n",
    "    S_model = sm.Logit(np.asarray(time_df[\"A\"]), np.asarray(sm.add_constant(time_df[train_columns]))).fit().param\n",
    "    return(S_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] simulation_run calculates the causal effect over an  \n",
    "## established number of repetitions using the models for outcome (Y) \n",
    "## and the covariates (L) \n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def simulation_run(df, Y_model, L1_model_df, max_time): \n",
    "    reps = 10000\n",
    "    final_results_1 = np.empty(reps) \n",
    "\n",
    "    ### establishing treatment of interest\n",
    "    A_test = [1]*max_time\n",
    "\n",
    "    for ii in range(0,reps):\n",
    "        values = np.empty(max_time)\n",
    "        values[0] = random.choice(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "        if values[0] == 0: \n",
    "            prod = 1-np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "        else: \n",
    "            prod = np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "\n",
    "        for jj in range(1, max_time):\n",
    "            if jj == 1: \n",
    "                values[1] = np.sum(np.array([L1_model_df.ix[jj-1,][i] for i in [1,2,4]])*[1,values[jj-1],A_test[jj-1]])\n",
    "            else: \n",
    "                values[jj] = np.sum(np.array([L1_model_df.ix[jj-1,][i] for i in range(1,6)])*[1,values[jj-1],values[jj-2], A_test[jj-1], A_test[jj-2]])\n",
    "            prod = prod*(np.exp(values[jj])/(1+np.exp(values[jj])))\n",
    "\n",
    "        list1 = [A_test[max_time-i] for i in range(1,5)]\n",
    "        list2 = [values[max_time-i] for i in range(1,5)]\n",
    "\n",
    "        result = [None]*(len(list1)+len(list2))\n",
    "        result[::2] = list1\n",
    "        result[1::2] = list2\n",
    "        result = [1] + result\n",
    "\n",
    "        Y_exp = np.sum(np.array(Y_model.params)*result)\n",
    "\n",
    "        final_results_1[ii] = prod*Y_exp\n",
    "\n",
    "    mean_1 = np.mean(final_results_1)\n",
    "\n",
    "\n",
    "    final_results_0 = np.empty(reps) \n",
    "    A_test = [0]*max_time\n",
    "\n",
    "    for ii in range(0,reps):\n",
    "        values = np.empty(max_time)\n",
    "        values[0] = random.choice(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "        if values[0] == 0: \n",
    "            prod = 1-np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "        else: \n",
    "            prod = np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "\n",
    "        for jj in range(1, max_time):\n",
    "            if jj == 1: \n",
    "                values[1] = np.sum(np.array([L1_model_df.ix[jj-1,][i] for i in [1,2,4]])*[1,values[jj-1],A_test[jj-1]])\n",
    "            else: \n",
    "                values[jj] = np.sum(np.array([L1_model_df.ix[jj-1,][i] for i in range(1,6)])*[1,values[jj-1],values[jj-2], A_test[jj-1], A_test[jj-2]])\n",
    "            prod = prod*(np.exp(values[jj])/(1+np.exp(values[jj])))\n",
    "\n",
    "        list1 = [A_test[max_time-i] for i in range(1,5)]\n",
    "        list2 = [values[max_time-i] for i in range(1,5)]\n",
    "\n",
    "        result = [None]*(len(list1)+len(list2))\n",
    "        result[::2] = list1\n",
    "        result[1::2] = list2\n",
    "        result = [1] + result\n",
    "\n",
    "        Y_exp = np.sum(np.array(Y_model.params)*result)\n",
    "\n",
    "        final_results_0[ii] = prod*Y_exp\n",
    "\n",
    "    mean_0 = np.mean(final_results_0)\n",
    "    final_answer = mean_1 - mean_0 \n",
    "    return(final_answer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.583506\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503166\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563181\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538506\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534821\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.549504\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558979\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.567018\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.552045\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.506334\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "## establishing constants \n",
    "indiv = 500   ## number of individuals in study \n",
    "max_time = 10 ## number of time points being considered \n",
    "t_delay = 2 ## number of time delays included in model \n",
    "num_sims = 50 \n",
    "results = np.empty(num_sims)\n",
    "\n",
    "## RUNNING SIMULATIONS \n",
    "start_time = time.time() \n",
    "for ii in range(num_sims):\n",
    "    print(ii) \n",
    "    [df, coefficient_df] = data_creation(indiv,max_time, 2) \n",
    "    Y_model = Y_model_creation(df, max_time)\n",
    "    L1_model_df = covariate_model_creation(df, max_time)\n",
    "    results[ii] = simulation_run(df, Y_model, L1_model_df, max_time)\n",
    "\n",
    "elapsed_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -9223372036854775808 is out of bounds for axis 1 with size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-ea3ee7cb98a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   2963\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2965\u001b[0;31m                       stacked=stacked, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   2966\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1818\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1819\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   5983\u001b[0m             \u001b[0;31m# this will automatically overwrite bins,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5984\u001b[0m             \u001b[0;31m# so that each histogram uses the same bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5985\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhist_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5986\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# causes problems later if it's an int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmlast\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;31m# The index computation is not guaranteed to give exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# consistent results within ~1 ULP of the bin edges.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0mdecrement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_a_data\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbin_edges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecrement\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# The last bin includes the right edge. The other bins do not.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index -9223372036854775808 is out of bounds for axis 1 with size 11"
     ]
    }
   ],
   "source": [
    "plt.hist(list(results[~np.isnan(results)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.284570679187241e-322"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results[~np.isnan(results)])\n",
    "# np.var(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Results = pd.DataFrame(results)\n",
    "Results.to_csv(\"SIM_RESULTS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOUBLY ROBUST METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indiv = 500 \n",
    "max_time = 10\n",
    "[df, coefficient_df] = data_creation(indiv,max_time, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indiv</th>\n",
       "      <th>time</th>\n",
       "      <th>U</th>\n",
       "      <th>A</th>\n",
       "      <th>Y</th>\n",
       "      <th>L1</th>\n",
       "      <th>L1_1</th>\n",
       "      <th>A_1</th>\n",
       "      <th>L1_2</th>\n",
       "      <th>A_2</th>\n",
       "      <th>L1_3</th>\n",
       "      <th>A_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.866350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.866350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    indiv  time         U    A    Y   L1  L1_1  A_1  L1_2  A_2  L1_3  A_3\n",
       "1     1.0   0.0  0.246552  0.0  NaN  1.0   NaN  NaN   NaN  NaN   NaN  NaN\n",
       "2     1.0   1.0  0.246552  0.0  NaN  1.0   1.0  0.0   NaN  NaN   NaN  NaN\n",
       "3     1.0   2.0  0.246552  0.0  NaN  1.0   1.0  0.0   1.0  0.0   NaN  NaN\n",
       "4     1.0   3.0  0.246552  0.0  NaN  1.0   1.0  0.0   1.0  0.0   1.0  0.0\n",
       "5     1.0   4.0  0.246552  0.0  NaN  0.0   1.0  0.0   1.0  0.0   1.0  0.0\n",
       "6     1.0   5.0  0.246552  0.0  NaN  1.0   0.0  0.0   1.0  0.0   1.0  0.0\n",
       "7     1.0   6.0  0.246552  0.0  NaN  1.0   1.0  0.0   0.0  0.0   1.0  0.0\n",
       "8     1.0   7.0  0.246552  1.0  NaN  1.0   1.0  0.0   1.0  0.0   0.0  0.0\n",
       "9     1.0   8.0  0.246552  0.0  NaN  1.0   1.0  1.0   1.0  0.0   1.0  0.0\n",
       "10    1.0   9.0  0.246552  0.0  NaN  1.0   1.0  0.0   1.0  1.0   1.0  0.0\n",
       "11    1.0  10.0  0.246552  1.0    0  1.0   1.0  0.0   1.0  0.0   1.0  1.0\n",
       "12    2.0   0.0  0.866350  1.0  NaN  0.0   1.0  1.0   1.0  0.0   1.0  0.0\n",
       "13    2.0   1.0  0.866350  1.0  NaN  0.0   0.0  1.0   1.0  1.0   1.0  0.0\n",
       "14    2.0   2.0  0.866350  0.0  NaN  1.0   0.0  1.0   0.0  1.0   1.0  1.0\n",
       "15    2.0   3.0  0.866350  1.0  NaN  1.0   1.0  0.0   0.0  1.0   0.0  1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ logit[P(A_{m,i} = 1 \\mid \\bar{l}_{m,i}, \\bar{a}_{m-1,i}; \\alpha )] = w_m (\\bar{l}_{m,i}, \\bar{a}_{m-1,i}; \\alpha) $$ \n",
    "\n",
    "\n",
    "\n",
    "\"Correct\" model:\n",
    "$$logit(P[\\hat{A}_{m,i}]) = \\alpha_0 + \\alpha_1 \\cdot L_{m,i} + \\alpha_2 \\cdot A_{m-1,i} + \\alpha_3 \\cdot L_{m-1,i} + \\alpha_4 \\cdot L_{m-2,i} + \\alpha_5 \\cdot A_{m-2,i} + \\alpha_6 \\cdot A_{m-3,i}$$ \n",
    "\n",
    "\"Incorrect model\":\n",
    "$$logit(P[\\hat{A}_{m,i}]) = \\alpha_0 + \\alpha_1 \\cdot L_{m-3,i} + \\alpha_2 \\cdot A_{m-3,i}$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] pi_function creates the w_m function given the following:\n",
    "## the alpha model of A_{m,i}, the dataframe, the time (m), and an \n",
    "## indicator of whether this is the correct or incorrect model \n",
    "\n",
    "## do I need to do something in here like 1-expit for those A_j == 0?? \n",
    "## i.e. what I did in the last line here \n",
    "#########################################################################\n",
    "\n",
    "def pi_function(m, alpha_model, df, indiv, alpha_wrong): \n",
    "    product = [1]*indiv\n",
    "    for jj in range(2, m+1): \n",
    "        if alpha_wrong == \"FALSE\": \n",
    "            x = np.sum(alpha_model*np.array(sm.add_constant(df[df.time == jj][[\"L1\", \"A_1\", \\\n",
    "                \"L1_1\", \"L1_2\", \"A_2\"]])), axis = 1) \n",
    "        else: \n",
    "            x = np.sum(alpha_model*np.array(sm.add_constant(df[df.time == jj][[\"L1_3\", \"A_3\"]])), axis = 1)\n",
    "        product = product*sp.special.expit(x)\n",
    "    \n",
    "    x = np.array(np.divide([1]*indiv, product))\n",
    "    x[np.where(df[df.time == m][\"A_1\"] == 0.0)] = 1 - x[np.where(df[df.time == m][\"A_1\"] == 0.0)]\n",
    "    return(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] alpha_model_creation creates the logistic regression \n",
    "## for the observed treatment (A) data from the current and previous \n",
    "## covariates and the previous treatments (A) over all time periods and\n",
    "## individuals \n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def alpha_model_creation(df, wrong): \n",
    "    alpha_df = pd.DataFrame(columns = [\"A\", \"l\", \"a_1\", \"l_1\", \"l_2\", \"l_3\", \"a_2\", \"a_3\"])\n",
    "    # First create a new dataset of all individuals \n",
    "    for ii in range(1,len(df)): \n",
    "        if df.loc[ii].time > 2.0:\n",
    "            alpha_df.loc[len(alpha_df)+1] = [df.loc[ii].A, df.loc[ii].L1, df.loc[ii][\"A_1\"], \\\n",
    "                                             df.loc[ii][\"L1_1\"], df.loc[ii][\"L1_2\"],  df.loc[ii][\"L1_3\"], \\\n",
    "                                             df.loc[ii][\"A_2\"], df.loc[ii][\"A_3\"]]\n",
    "\n",
    "    if wrong == \"TRUE\":\n",
    "        alpha_model = sm.Logit(np.asarray(alpha_df.A),np.asarray(sm.add_constant(alpha_df[[\"l_3\", \"a_3\"]]))).fit().params\n",
    "    else: \n",
    "        alpha_model = sm.Logit(np.asarray(alpha_df.A),np.asarray(sm.add_constant(alpha_df[[\"l\", \"a_1\", \"l_1\",\\\n",
    "                      \"l_2\", \"a_2\"]]))).fit().params\n",
    "    return(alpha_model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] DR_estimate_creation calculates the causal effect for a \n",
    "## given treatment of interest (test_value), including an indicator \n",
    "## of whether the correct or incorrect model is being used \n",
    "\n",
    "#########################################################################\n",
    "\n",
    "def DR_estimate_creation(test_value, max_time, df, indiv, wrong_model):\n",
    "    alpha_model = alpha_model_creation(df,wrong_model)\n",
    "    \n",
    "    A_test = [test_value]*indiv \n",
    "    model_df = pd.DataFrame(columns = [\"time\", \"beta_0\", \"beta_1\", \"beta_2\", \\\n",
    "                \"beta_3\", \"beta_4\", \"beta_5\", \"beta_6\", \"phi\"])\n",
    "    time.counter = max_time\n",
    "    T = list(df[df.time == max_time].Y)\n",
    "\n",
    "    while(time.counter > 2.0): \n",
    "        time_df = df.loc[df.time == time.counter]\n",
    "        time_df[\"T\"] = np.array(T)\n",
    "        pi = pi_function(time.counter, alpha_model, df, indiv, wrong_model) \n",
    "        time_df[\"pi\"] = pi \n",
    "        train_columns ='+'.join(map(str, np.append(list(time_df)[6:12], \\\n",
    "                        list(time_df)[13])))\n",
    "        time_df = time_df.astype(float)\n",
    "        S_model = smf.ols(\"T~\"+train_columns, data=time_df).fit()\n",
    "        model_df = model_df.append(pd.DataFrame([time.counter] + \\\n",
    "                   [S_model.params[i] for i in range(0,8)]).transpose(), ignore_index=True)\n",
    "        time_df[\"A_1\"] = np.array(A_test)\n",
    "        new_T = np.sum([S_model.params[i] for i in range(0,8)]*\\\n",
    "                np.array(sm.add_constant(time_df.loc[:,np.append(list(time_df)[6:12], \\\n",
    "                list(time_df)[13])], has_constant='add')), axis=1)\n",
    "        T = sp.special.expit(new_T)\n",
    "        time.counter = time.counter-1\n",
    "    \n",
    "    return(np.nanmean(T))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689337\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689337\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.33338266295e-06\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653635\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653635\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.97203628059e-07\n"
     ]
    }
   ],
   "source": [
    "print(DR_estimate_creation(1.0, max_time, df, indiv, \"TRUE\")-DR_estimate_creation(0.0, max_time, df, indiv, \"TRUE\"))\n",
    "\n",
    "print(DR_estimate_creation(1.0, max_time, df, indiv, \"FALSE\") - DR_estimate_creation(0.0, max_time, df, indiv, \"FALSE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
