{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can establish our framework by defining the variables to be used.  We start with the outcome variable, $Y$.  Next, we consider out treatment variable, $A_k$, which takes on value 1 if there is treatment, and is 0 otherwise.  To begin, we will use treatment strategies that are exclusively treatment or exclusively no treatment, corresponding to $\\overline{a} = (1,1,\\dots,1) = \\overline{1}$ and $\\overline{a} = (0,0,\\dots,0) = \\overline{0}$ respectively.  The next measurable variable is $L$, which represents the covariate(s) to be included.  Note that both the covariates, $L$, and the outcome, $Y$ are affected by an unmeasured common cause, $U$.  The diagram below illustrates these relationships.  \n",
    "\n",
    "![title](image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Creation\n",
    "\n",
    "We first need to simulate the data. We will build out the covariates of the population.  For simplicity, we will use one binary covariate, $L_1$.  \n",
    "\n",
    "The data is being simulated using the following equations, where U is an underlying confounder.  \n",
    "\n",
    "$$logitP[L_k] = \\alpha_0 + \\alpha_1 \\cdot L_{k-1} + \\alpha_2 \\cdot L_{k-2} + \\alpha_3 A_{k-1} + \\alpha_4 A_{K-2} + \\alpha_5 U$$ \n",
    "\n",
    "\n",
    "$$ logit[A_k] = \\beta_0 + \\beta_1 L_{k} + \\beta_2 L_{k-1} + \\beta_3 A_{k-1} + \\beta_4 A_{K-2} $$ \n",
    "\n",
    "Then, an end $Y$ value will be pulled from the following \n",
    "$$ Y \\sim N(\\mu = U, \\sigma = 1) $$ \n",
    "\n",
    "where $U \\sim Unif(0.1, 1)$ \n",
    "\n",
    "\n",
    "## G-formula Simulation Study \n",
    "\n",
    "The purpose of this investigation is to measure the average causal effect of treatment, which can be estimated using \n",
    "$$ \\mathbb{E}\\big[Y^{a=1}\\big] - \\mathbb{E}\\big[Y^{a=0}\\big]$$ \n",
    "for the respective $\\bar{a} = \\bar{0}$ and $\\bar{a} = \\bar{1}$\n",
    "\n",
    "We want to build out the g-formula as follows  \n",
    "$$ \\mathbb{E} \\big[Y^{\\overline{a}}\\big]  = \\sum_{l_i} \\mathbb{E} \\big[Y \\mid A_{0} = a_{0},  \\; A_{1} = a_{1}, \\cdots, \\; A_{t} = a_{t},  \\; L_{0} = l_0, \\; L_{1} = l_1, \\cdots, \\; L_{t} = l_t,\\big] \\prod_{k=0}^t P(L_k = l_k \\mid \\overline{L}_{k-1}, \\overline{A}_{k-1})  $$\n",
    "\n",
    "We can do this by building out two models, one for $Y$ And one for $L$.  We will begin by using a continous $Y$ and a binary $L$ for simplicity.  \n",
    "\n",
    "For $Y$, we will use a linear regression, and the model will look something like this \n",
    "\n",
    "$$\\mathbb{E} \\big[Y \\mid \\overline{A}_t, \\overline{L}_t \\big] = \\theta_{0} + \\theta_1 A_{t}+ \\theta_2 A_{t-1} + \\cdots + \\theta_j A_0 + \\theta_{j+1} L_t + \\theta_{j+2} L_{t-1} + \\cdots + \\theta_{j+k} L_0 $$ \n",
    "\n",
    "For each $L$, we will use a logistic regression, also calculated on a time delay of t=2.  This will give us something similar to \n",
    "\n",
    "$$ logit(L_k) = \\gamma_0 + \\gamma_1 L_{k-1} + \\gamma_2 L_{k-2} + \\gamma_3 A_{k-1} + \\gamma_4 A_{k-2} $$ \n",
    "\n",
    "For the treatment $A$, we will also use a logistic regression on a time delay of 2, similar to, \n",
    "$$ logit(A_k) = \\zeta_0 + \\zeta_1 L_{k} + \\zeta_2 L_{k-1} + \\zeta_3 A_{k-1} + \\zeta_4 A_{k-2} $$ \n",
    "\n",
    "\n",
    "\n",
    "Using these models, I simulated 500 mean casual effects for 500 individual datasets.  \n",
    "<!---what quadratic time term needed to be added here? --->\n",
    "\n",
    "## Results \n",
    "Mean of means of differences: 1.7217286172967964e-07\n",
    "\n",
    "Variance of means of differences: 2.3894070465421745e-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import math\n",
    "import csv\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] data_creation simulates data for a given number of \n",
    "## individuals(indiv) over a set amount of time (max_time), and can \n",
    "## include as many covariates as desired (number_of_covariates)\n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def data_creation(indiv, max_time, number_of_covariates, Y_full, alpha, beta): \n",
    "\n",
    "    columns = [\"indiv\", \"time\",\"U\", \"A\", \"Y\",  \"L1\"]\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    for ii in range(1,indiv+1):\n",
    "     \n",
    "        ## creating an unobserved variable that affects covariates \n",
    "        U = np.random.uniform(low = 0.1, high = 1 )\n",
    "            \n",
    "        for jj in range(0, max_time+1): \n",
    "            if jj == 0: \n",
    "                x_L = alpha[0] + alpha[5]*U \n",
    "                L1 = np.random.binomial(n=1, p = np.exp(x_L)/(1+np.exp(x_L)))\n",
    "\n",
    "                x_A = beta[0] + beta[1]*L1 \n",
    "                A = np.random.binomial(n=1, p = np.exp(x_A)/(1+np.exp(x_A)))\n",
    "\n",
    "                df.loc[len(df)+1] = [ii, jj, U, A, \"NaN\",  L1]\n",
    "\n",
    "            elif jj == 1: \n",
    "                x_L = np.sum(alpha*np.array([1, float(df[\"L1\"][(df.time == jj-1) & (df.indiv == ii)]), \\\n",
    "                            0, float(df[\"A\"][(df.time == jj-1) & (df.indiv == ii)]), 0, U]))\n",
    "                \n",
    "                L1 = np.random.binomial(n=1, p = np.exp(x_L)/(1+np.exp(x_L)))\n",
    "                \n",
    "                \n",
    "                x_A = np.sum(beta*np.array([1.0,L1, float(df[\"L1\"][(df.time == jj-1) & (df.indiv == ii)]), \\\n",
    "                      float(df[\"A\"][(df.time == jj-1) & (df.indiv == ii)]), 0.0]))\n",
    "                \n",
    "                A = np.random.binomial(n=1, p = np.exp(x_A)/(1+np.exp(x_A)))\n",
    "\n",
    "                df.loc[len(df)+1] = [ii, jj, U, A, \"NaN\", L1]\n",
    "\n",
    "            else: \n",
    "                x_L = np.sum(alpha*np.array([1, float(df[\"L1\"][(df.time == jj-1) & (df.indiv == ii)]), \\\n",
    "                      float(df[\"L1\"][(df.time == jj-2) & (df.indiv == ii)]), float(df[\"A\"]\\\n",
    "                      [(df.time == jj-1) & (df.indiv == ii)]), float(df[\"A\"][(df.time == jj-2)\\\n",
    "                      & (df.indiv == ii)]), U]))\n",
    "                \n",
    "                L1 = np.random.binomial(n=1, p = np.exp(x_L)/(1+np.exp(x_L)))\n",
    "\n",
    "\n",
    "                x_A = np.sum(beta*np.array([1,L1,float(df[\"L1\"][(df.time == jj-1) & (df.indiv == ii)]), \\\n",
    "                      float(df[\"A\"][(df.time == jj-1) & (df.indiv == ii)]), float(df[\"A\"]\\\n",
    "                    [(df.time == jj-2) & (df.indiv == ii)])]))\n",
    "                \n",
    "                A = np.random.binomial(n=1, p = np.exp(x_A)/(1+np.exp(x_A)))\n",
    "\n",
    "                if jj == max_time: \n",
    "                    x_Y = 0.5 + U \n",
    "                    Y = np.random.binomial(n=1, p = np.exp(x_Y)/(1+np.exp(x_Y)))\n",
    "                    df.loc[len(df)+1] = [ii, jj, U, A, Y, L1]\n",
    "\n",
    "                else: \n",
    "                    df.loc[len(df)+1] = [ii, jj, U, A, \"NaN\", L1]\n",
    "\n",
    "    # creating shifted values \n",
    "    if Y_full == \"TRUE\":\n",
    "        for kk in range(1,max_time+1):\n",
    "            df[\"L1_\"+str(kk)] = df.L1.shift(kk)\n",
    "            df[\"A_\"+str(kk)] = df.A.shift(kk)\n",
    "    else:\n",
    "        for kk in range(1,4):\n",
    "            df[\"L1_\"+str(kk)] = df.L1.shift(kk)\n",
    "            df[\"A_\"+str(kk)] = df.A.shift(kk)\n",
    "\n",
    "    return(df); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] data_creation simulates data for a given number of \n",
    "## individuals(indiv) over a set amount of time (max_time), and can \n",
    "## include as many covariates as desired (number_of_covariates)\n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def data_creation2(indiv, max_time, number_of_covariates, Y_full, alpha, beta): \n",
    "\n",
    "    columns = [\"indiv\", \"time\",\"U\", \"A\", \"Y\",  \"L1\"]\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "     \n",
    "    ## creating an unobserved variable that affects covariates \n",
    "    U = np.random.uniform(low = 0.1, high = 1, size = indiv)\n",
    "            \n",
    "    for jj in range(0, max_time+1): \n",
    "        if jj == 0: \n",
    "            x_L = alpha[0] + alpha[5]*U \n",
    "            L1 = np.random.binomial(n=1, p = np.exp(x_L)/(1+np.exp(x_L)))\n",
    "\n",
    "            x_A = beta[0] + beta[1]*L1 \n",
    "            A = np.random.binomial(n=1, p = np.exp(x_A)/(1+np.exp(x_A)))\n",
    "\n",
    "            df = pd.DataFrame({\"indiv\":range(1,indiv+1), \"time\":jj,\"U\":U, \"A\":A, \"Y\":[\"Nan\"]*indiv, \"L1\":L1})\n",
    "            \n",
    "        elif jj == 1: \n",
    "            x_L = np.sum(alpha*np.transpose(np.array([[1.0]*indiv, df[\"L1\"][(df.time == jj-1)], \\\n",
    "                        [0.0]*indiv, df[\"A\"][(df.time == jj-1)], [0.0]*indiv, U])), axis = 1)\n",
    "\n",
    "            L1 = np.random.binomial(n=1, p = np.exp(x_L)/(1+np.exp(x_L)))\n",
    "\n",
    "\n",
    "            x_A = np.sum(beta*np.transpose(np.array([[1.0]*indiv, L1, df[\"L1\"][(df.time == jj-1)],\\\n",
    "                  df[\"A\"][(df.time == jj-1)], [0.0]*indiv ])), axis = 1)\n",
    "                         \n",
    "            A = np.random.binomial(n=1, p = np.exp(x_A)/(1+np.exp(x_A)))\n",
    "\n",
    "            temp_df = pd.DataFrame({\"indiv\":range(1,indiv+1), \"time\":jj, \"U\":U, \"A\":A, \"Y\":[\"Nan\"]*indiv, \"L1\":L1})\n",
    "            df = pd.concat([df, temp_df])\n",
    "\n",
    "        else: \n",
    "            x_L = np.sum(alpha*np.transpose(np.array([[1.0]*indiv, df[\"L1\"][(df.time == jj-1)], \\\n",
    "                  df[\"L1\"][(df.time == jj-2)], df[\"A\"][(df.time == jj-1)], \\\n",
    "                  df[\"A\"][(df.time == jj-2)], U])), axis = 1)\n",
    "\n",
    "            L1 = np.random.binomial(n=1, p = np.exp(x_L)/(1+np.exp(x_L)))\n",
    "\n",
    "\n",
    "            x_A = np.sum(beta*np.transpose(np.array([[1.0]*indiv,L1,df[\"L1\"][(df.time == jj-1)], \\\n",
    "                  df[\"A\"][(df.time == jj-1)] , df[\"A\"][(df.time == jj-2)]])), axis = 1)\n",
    "\n",
    "            A = np.random.binomial(n=1, p = np.exp(x_A)/(1+np.exp(x_A)))\n",
    "\n",
    "            if jj == max_time: \n",
    "                x_Y = 0.5 + U \n",
    "                Y = np.random.binomial(n=1, p = np.exp(x_Y)/(1+np.exp(x_Y)))                \n",
    "                temp_df = pd.DataFrame({\"indiv\":range(1,indiv+1), \"time\":jj,\"U\":U, \"A\":A, \"Y\":Y, \"L1\":L1})\n",
    "                df = pd.concat([df, temp_df])\n",
    "\n",
    "\n",
    "            else: \n",
    "                temp_df = pd.DataFrame({\"indiv\":range(1,indiv+1), \"time\":jj,\"U\":U, \"A\":A, \"Y\":[\"Nan\"]*indiv, \"L1\":L1})\n",
    "                df = pd.concat([df, temp_df])\n",
    "\n",
    "\n",
    "    # creating shifted values \n",
    "    if Y_full == \"TRUE\":\n",
    "        for kk in range(1,max_time+1):\n",
    "            df[\"L1_\"+str(kk)] = df.L1.shift(kk)\n",
    "            df[\"A_\"+str(kk)] = df.A.shift(kk)\n",
    "    else:\n",
    "        for kk in range(1,4):\n",
    "            df[\"L1_\"+str(kk)] = df.L1.shift(kk)\n",
    "            df[\"A_\"+str(kk)] = df.A.shift(kk)\n",
    "            \n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return(df); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] Y_model_creation creates the linear regression model for \n",
    "## the observed Ys based on the treatments (A) and covariates (L)  \n",
    "\n",
    "#########################################################################\n",
    "\n",
    "def Y_model_creation(df, max_time): \n",
    "    temp_df = df[df.time == max_time]\n",
    "    train_columns ='+'.join(map(str, np.append(list(df)[0:2],list(df)[6:])))\n",
    "    temp_df = temp_df.astype(float)\n",
    "    Y_model = smf.ols(\"Y~\"+train_columns, data=temp_df).fit(); \n",
    "    return(Y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] covariate_model_creation creates the logistic regression \n",
    "## for the observed covariate (L) data from the previous covariates \n",
    "## and the previous treatments (A) \n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "## SHOULD THIS BE FOR ALL HISTORY UP TO THAT POINT TO BE MORE \n",
    "## ACCURATE WHEN CALCULATING THE EXPECTATION??? \n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def covariate_model_creation(df, max_time): \n",
    "    columns = [\"time\", \"gamma_0\", \"gamma_1\", \"gamma_2\", \"gamma_3\", \"gamma_4\", \\\n",
    "              \"gamma_5\", \"gamma_6\"]\n",
    "    train_columns = [\"L1_1\", \"L1_2\", \"L1_3\", \"A_1\", \"A_2\",  \"A_3\"]\n",
    "    L1_model_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "    for ii in range(1, (max_time+1)): \n",
    "        temp_df = df[df.time == ii] \n",
    "        if ii == 1: \n",
    "            L1_model = sm.Logit(np.asarray(temp_df[\"L1\"]), \\\n",
    "                       np.asarray(sm.add_constant(temp_df[[\"L1_1\", \"A_1\"]]))).fit(); \n",
    "            L1_model_df = L1_model_df.append(pd.DataFrame([ii] + \\\n",
    "                         [L1_model.params[i] for i in range(0,2)] + [\"Nan\"] + \\\n",
    "                         [\"Nan\"] + [L1_model.params[2]] + [\"Nan\"] + [\"Nan\"], \\\n",
    "                         index = columns).transpose(), ignore_index=True)\n",
    "        elif ii == 2: \n",
    "            L1_model = sm.Logit(np.asarray(temp_df[\"L1\"]), \\\n",
    "                       np.asarray(sm.add_constant(temp_df[[\"L1_1\", \"L1_2\", \\\n",
    "                       \"A_1\", \"A_2\"]]))).fit(); \n",
    "            L1_model_df = L1_model_df.append(pd.DataFrame([ii] + [L1_model.params[i] \\\n",
    "                          for i in range(0,3)] + [\"Nan\"] + [L1_model.params[i] for i \\\n",
    "                          in range(3,5)] + [\"Nan\"], index = columns).transpose(), ignore_index=True)\n",
    "        else: \n",
    "            L1_model = sm.Logit(np.asarray(temp_df[\"L1\"]), \\\n",
    "                       np.asarray(sm.add_constant(temp_df[train_columns]))).fit(); \n",
    "            L1_model_df = L1_model_df.append(pd.DataFrame([ii] + [L1_model.params[i] for \\\n",
    "                          i in range(0,7)], index = columns).transpose(), ignore_index=True)\n",
    "    return(L1_model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ logit(L_k) = \\gamma_0 + \\gamma_1 L_{k-1} + \\gamma_2 L_{k-2} + \\gamma_3 L_{k-3} + \\gamma_4 A_{k-1} + \\gamma_5 A_{k-2} + \\gamma_6 A_{k-3} $$ \n",
    "\n",
    "$$ logit(A_k) = \\zeta_0 + \\zeta_1 L_{k} + \\zeta_2 L_{k-1} + \\zeta_3 A_{k-1} + \\zeta_4 A_{k-2} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] treatment_model_creation creates the logistic regression \n",
    "## for the observed treatment (A) data from the current and previous \n",
    "## covariates and the previous treatments (A) \n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def treatment_model_creation(df, max_time): \n",
    "    columns = [\"time\", \"zeta_0\", \"zeta_1\", \"zeta_2\", \"zeta_3\", \"zeta_4\"]\n",
    "    train_columns = [\"L1\", \"L1_1\", \"A_1\", \"A_2\"]\n",
    "    A_model_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "    for ii in range(1, (max_time+1)): \n",
    "        temp_df = df[df.time == ii]   \n",
    "        if ii == 1: \n",
    "            A_model = sm.Logit(np.asarray(temp_df[\"A\"]), np.asarray(sm.add_constant(temp_df[[\"L1\", \\\n",
    "                      \"L1_1\", \"A_1\"]]))).fit()\n",
    "            A_model_df = A_model_df.append(pd.DataFrame([ii] + [A_model.params[i] for i in range(0,4)]\\\n",
    "                         + [\"Nan\"], index = columns).transpose(), ignore_index=True)\n",
    "        else: \n",
    "            A_model = sm.Logit(np.asarray(temp_df[\"A\"]), np.asarray(sm.add_constant(temp_df[train_columns]))).fit()\n",
    "            A_model_df = A_model_df.append(pd.DataFrame([ii] + [A_model.params[i] for i in range(0,5)],\\\n",
    "                         index = columns).transpose(), ignore_index=True)\n",
    "    return(A_model_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] simulation_run calculates the causal effect over an  \n",
    "## established number of repetitions using the models for outcome (Y) \n",
    "## and the covariates (L) \n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def simulation_run(df, Y_model, L1_model_df, max_time, Y_full, test_value): \n",
    "    reps = 10000\n",
    "    final_results = np.empty(reps) \n",
    "\n",
    "    ### establishing treatment of interest\n",
    "    A_test = [test_value]*max_time\n",
    "\n",
    "    for ii in range(0,reps):\n",
    "        values = np.empty(max_time)\n",
    "        values[0] = random.choice(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "        if values[0] == 0: \n",
    "            prod = 1-np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "        else: \n",
    "            prod = np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "\n",
    "        for jj in range(1, max_time):\n",
    "            if jj == 1: \n",
    "                values[jj] = np.sum(np.array([L1_model_df.ix[jj-1,][i] for i \\\n",
    "                             in [1,2,5]])*[1.0,values[jj-1],A_test[jj-1]])\n",
    "            elif jj == 2: \n",
    "                values[jj] = np.sum(np.array([L1_model_df.ix[jj-1,][i] for i \\\n",
    "                             in [1,2,3,5,6]])*[1.0,values[jj-1],values[jj-2], \\\n",
    "                             A_test[jj-1], A_test[jj-2]])\n",
    "            else: \n",
    "                values[jj] = np.sum(np.array([L1_model_df.ix[jj-1,][i] for i \\\n",
    "                             in range(1,8)])*[1.0,values[jj-1],values[jj-2], \\\n",
    "                             values[jj-2], A_test[jj-1], A_test[jj-2], A_test[jj-3]])\n",
    "            prod = prod*(np.exp(values[jj])/(1+np.exp(values[jj])))\n",
    "\n",
    "        if Y_full == \"TRUE\": \n",
    "            list1 = [A_test[max_time-i] for i in range(1,max_time+2)]\n",
    "            list2 = [values[max_time-i] for i in range(1,max_time+2)]\n",
    "\n",
    "        else: \n",
    "            list1 = [A_test[max_time-i] for i in range(1,5)]\n",
    "            list2 = [values[max_time-i] for i in range(1,5)]\n",
    "            \n",
    "        result = [None]*(len(list1)+len(list2))\n",
    "        result[::2] = list1\n",
    "        result[1::2] = list2\n",
    "        result = [1] + result\n",
    "\n",
    "        Y_exp = np.sum(np.array(Y_model.params)*result)\n",
    "\n",
    "        final_results[ii] = prod*Y_exp\n",
    "\n",
    "    return(np.mean(final_results)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] simulation_run calculates the causal effect over an  \n",
    "## established number of repetitions using the models for outcome (Y) \n",
    "## and the covariates (L) \n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def simulation_run2(df, Y_model, L1_model_df, max_time, Y_full, test_value): \n",
    "    reps = 1000\n",
    "    final_results = np.empty(reps) \n",
    "\n",
    "    ### establishing treatment of interest\n",
    "    A_test = [test_value]*(max_time+1) \n",
    "\n",
    "    values = pd.DataFrame(np.random.choice(np.array(df[\"L1\"][df[\"time\"] == 0]), reps))\n",
    "    prod = np.empty(reps) \n",
    "\n",
    "    prod[values[[0]] == 0 ] = 1-np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "    prod[values[[0]] != 0] = np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "\n",
    "    values[1] = np.sum(np.array([L1_model_df.ix[0,][i] for i in [1,2,5]])*np.transpose(np.array([[1.0]*reps,list(values[0]),[A_test[0]]*reps])), axis = 1)\n",
    "    prod = prod*(np.exp(values[1])/(1+np.exp(values[1])))\n",
    "\n",
    "    values[2] = np.sum(np.array([L1_model_df.ix[1,][i] for i \\\n",
    "                         in [1,2,3,5,6]])*np.transpose(np.array([[1.0]*reps, list(values[1]),list(values[0]), \\\n",
    "                         [A_test[1]]*reps, [A_test[0]]*reps])), axis = 1 )\n",
    "    prod = prod*(np.exp(values[2])/(1+np.exp(values[2])))                                                            \n",
    "\n",
    "    for jj in range(3, max_time+1):\n",
    "        values[jj] = np.sum(np.array([L1_model_df.ix[jj-1,][i] for i in range(1,8)])*np.transpose(np.array([[1.0]*reps,list(values[jj-1]),list(values[jj-2]), list(values[jj-2]), [A_test[jj-1]]*reps, [A_test[jj-2]]*reps, [A_test[jj-3]]*reps])), axis = 1)\n",
    "        prod = prod*(np.exp(values[jj])/(1+np.exp(values[jj])))\n",
    "        \n",
    "    values.head(250)\n",
    "\n",
    "    if Y_full == \"TRUE\": \n",
    "        Y_A = [A_test]*reps\n",
    "        Y_L = np.array(values)\n",
    "        Y_exp = np.array(Y_model.params[0])*([1.0]*reps) + np.sum(Y_A*np.array([Y_model.params[i]\\\n",
    "                for i in [1,4,6,8,10,12,14,16,18,20,22,24]]), axis = 1)+np.sum([Y_model.params[i] for i in \\\n",
    "                [2,3,5,7,9,11,13,15,17,19,21,23]]*Y_L, axis = 1)\n",
    "    else: \n",
    "        Y_A = [A_test*4]*reps\n",
    "        Y_L = np.array([values[0], values[1], values[2], values[3], values[4]])\n",
    "        Y_exp = np.array(Y_model.params[0])*([1.0]*reps) + np.sum(Y_A*np.array([Y_model.params[i]\\\n",
    "                for i in [1,4,6,8]]), axis = 1)+np.sum([Y_model.params[i] for i in \\\n",
    "                [2,3,5,7]]*Y_L, axis = 1)\n",
    "\n",
    "    return(np.mean(prod*Y_exp)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:10: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>1.111254</td>\n",
       "      <td>1.067103</td>\n",
       "      <td>1.214161</td>\n",
       "      <td>1.665270</td>\n",
       "      <td>2.240954</td>\n",
       "      <td>0.725185</td>\n",
       "      <td>1.243461</td>\n",
       "      <td>1.677858</td>\n",
       "      <td>1.541395</td>\n",
       "      <td>1.811500</td>\n",
       "      <td>1.025072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1.102624</td>\n",
       "      <td>1.037928</td>\n",
       "      <td>1.212345</td>\n",
       "      <td>1.647352</td>\n",
       "      <td>2.241282</td>\n",
       "      <td>0.726519</td>\n",
       "      <td>1.243407</td>\n",
       "      <td>1.678194</td>\n",
       "      <td>1.541529</td>\n",
       "      <td>1.811529</td>\n",
       "      <td>1.025040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0     0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "1     0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "2     1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "3     0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "4     1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "5     1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "6     1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "7     1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "8     1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "9     0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "10    0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "11    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "12    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "13    0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "14    0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "15    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "16    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "17    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "18    0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "19    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "20    0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "21    0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "22    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "23    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "24    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "25    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "26    0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "27    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "28    1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "29    0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "..   ..       ...       ...       ...       ...       ...       ...       ...   \n",
       "220   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "221   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "222   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "223   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "224   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "225   0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "226   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "227   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "228   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "229   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "230   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "231   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "232   0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "233   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "234   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "235   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "236   0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "237   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "238   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "239   0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "240   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "241   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "242   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "243   0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "244   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "245   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "246   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "247   0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "248   0  1.111254  1.067103  1.214161  1.665270  2.240954  0.725185  1.243461   \n",
       "249   1  1.102624  1.037928  1.212345  1.647352  2.241282  0.726519  1.243407   \n",
       "\n",
       "           8         9         10        11  \n",
       "0    1.677858  1.541395  1.811500  1.025072  \n",
       "1    1.677858  1.541395  1.811500  1.025072  \n",
       "2    1.678194  1.541529  1.811529  1.025040  \n",
       "3    1.677858  1.541395  1.811500  1.025072  \n",
       "4    1.678194  1.541529  1.811529  1.025040  \n",
       "5    1.678194  1.541529  1.811529  1.025040  \n",
       "6    1.678194  1.541529  1.811529  1.025040  \n",
       "7    1.678194  1.541529  1.811529  1.025040  \n",
       "8    1.678194  1.541529  1.811529  1.025040  \n",
       "9    1.677858  1.541395  1.811500  1.025072  \n",
       "10   1.677858  1.541395  1.811500  1.025072  \n",
       "11   1.678194  1.541529  1.811529  1.025040  \n",
       "12   1.678194  1.541529  1.811529  1.025040  \n",
       "13   1.677858  1.541395  1.811500  1.025072  \n",
       "14   1.677858  1.541395  1.811500  1.025072  \n",
       "15   1.678194  1.541529  1.811529  1.025040  \n",
       "16   1.678194  1.541529  1.811529  1.025040  \n",
       "17   1.678194  1.541529  1.811529  1.025040  \n",
       "18   1.677858  1.541395  1.811500  1.025072  \n",
       "19   1.678194  1.541529  1.811529  1.025040  \n",
       "20   1.677858  1.541395  1.811500  1.025072  \n",
       "21   1.677858  1.541395  1.811500  1.025072  \n",
       "22   1.678194  1.541529  1.811529  1.025040  \n",
       "23   1.678194  1.541529  1.811529  1.025040  \n",
       "24   1.678194  1.541529  1.811529  1.025040  \n",
       "25   1.678194  1.541529  1.811529  1.025040  \n",
       "26   1.677858  1.541395  1.811500  1.025072  \n",
       "27   1.678194  1.541529  1.811529  1.025040  \n",
       "28   1.678194  1.541529  1.811529  1.025040  \n",
       "29   1.677858  1.541395  1.811500  1.025072  \n",
       "..        ...       ...       ...       ...  \n",
       "220  1.678194  1.541529  1.811529  1.025040  \n",
       "221  1.678194  1.541529  1.811529  1.025040  \n",
       "222  1.678194  1.541529  1.811529  1.025040  \n",
       "223  1.678194  1.541529  1.811529  1.025040  \n",
       "224  1.678194  1.541529  1.811529  1.025040  \n",
       "225  1.677858  1.541395  1.811500  1.025072  \n",
       "226  1.678194  1.541529  1.811529  1.025040  \n",
       "227  1.678194  1.541529  1.811529  1.025040  \n",
       "228  1.678194  1.541529  1.811529  1.025040  \n",
       "229  1.678194  1.541529  1.811529  1.025040  \n",
       "230  1.678194  1.541529  1.811529  1.025040  \n",
       "231  1.678194  1.541529  1.811529  1.025040  \n",
       "232  1.677858  1.541395  1.811500  1.025072  \n",
       "233  1.678194  1.541529  1.811529  1.025040  \n",
       "234  1.678194  1.541529  1.811529  1.025040  \n",
       "235  1.678194  1.541529  1.811529  1.025040  \n",
       "236  1.677858  1.541395  1.811500  1.025072  \n",
       "237  1.678194  1.541529  1.811529  1.025040  \n",
       "238  1.678194  1.541529  1.811529  1.025040  \n",
       "239  1.677858  1.541395  1.811500  1.025072  \n",
       "240  1.678194  1.541529  1.811529  1.025040  \n",
       "241  1.678194  1.541529  1.811529  1.025040  \n",
       "242  1.678194  1.541529  1.811529  1.025040  \n",
       "243  1.677858  1.541395  1.811500  1.025072  \n",
       "244  1.678194  1.541529  1.811529  1.025040  \n",
       "245  1.678194  1.541529  1.811529  1.025040  \n",
       "246  1.678194  1.541529  1.811529  1.025040  \n",
       "247  1.677858  1.541395  1.811500  1.025072  \n",
       "248  1.677858  1.541395  1.811500  1.025072  \n",
       "249  1.678194  1.541529  1.811529  1.025040  \n",
       "\n",
       "[250 rows x 12 columns]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps = 1000\n",
    "final_results = np.empty(reps) \n",
    "\n",
    "### establishing treatment of interest\n",
    "A_test = [test_value]*(max_time+1) \n",
    "\n",
    "values = pd.DataFrame(np.random.choice(np.array(df[\"L1\"][df[\"time\"] == 0]), reps))\n",
    "prod = np.empty(reps) \n",
    "\n",
    "prod[values[[0]] == 0 ] = 1-np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "prod[values[[0]] != 0] = np.mean(list(df[\"L1\"][df[\"time\"] == 0]))\n",
    "\n",
    "values[1] = np.sum(np.array([L1_model_df.ix[0,][i] for i in [1,2,5]])*np.transpose(np.array([[1.0]*reps,list(values[0]),[A_test[0]]*reps])), axis = 1)\n",
    "prod = prod*(np.exp(values[1])/(1+np.exp(values[1])))\n",
    "\n",
    "\n",
    "values[2] = np.sum(np.array([L1_model_df.ix[1,][i] for i in [1,2,3,5,6]])*np.transpose(np.array([[1.0]*reps, list(values[0]), list(values[1]), [A_test[1]]*reps, [A_test[0]]*reps])), axis =1)\n",
    "prod = prod*(np.exp(values[2])/(1+np.exp(values[2])))                                                            \n",
    "\n",
    "\n",
    "for jj in range(3, max_time+1):\n",
    "  values[jj] = np.sum(np.array([L1_model_df.ix[jj-1,][i] for i in range(1,8)])*np.transpose(np.array([[1.0]*reps,list(values[jj-1]),list(values[jj-2]), list(values[jj-2]), [A_test[jj-1]]*reps, [A_test[jj-2]]*reps, [A_test[jj-3]]*reps])), axis = 1)\n",
    "  prod = prod*(np.exp(values[jj])/(1+np.exp(values[jj])))\n",
    "\n",
    "values.head(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.521503\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.493448\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.504559\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553813\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.416014\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.474845\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.492815\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.472614\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.484225\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490118\n",
      "         Iterations 6\n",
      "1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.644493\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.617283\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.599157\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.629631\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.610587\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.645524\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.631797\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.626374\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.629855\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637396\n",
      "         Iterations 5\n",
      "2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.640074\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540595\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657502\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654715\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608804\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592947\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.610871\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.632949\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.619869\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.633134\n",
      "         Iterations 5\n",
      "3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.561316\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.445401\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.432863\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.368471\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407773\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.369807\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.377405\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.377756\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.356583\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.332899\n",
      "         Iterations 7\n",
      "4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535991\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413572\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.357654\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.304031\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.399854\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.339049\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.371972\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.356348\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.339014\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.353091\n",
      "         Iterations 6\n",
      "5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650212\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608945\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.559537\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.583271\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.565315\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542336\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.560858\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579420\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581366\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.535372\n",
      "         Iterations 6\n",
      "6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.603814\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.595639\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566024\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.624603\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.585475\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605271\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.583299\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.614516\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602960\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.617359\n",
      "         Iterations 5\n",
      "7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.294057\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.313944\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.343412\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.402927\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.335779\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.340071\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.374326\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407102\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.374651\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.362380\n",
      "         Iterations 7\n",
      "8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538387\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.360275\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.357930\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.452848\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.446333\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.440679\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.399706\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.380178\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.438538\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.402956\n",
      "         Iterations 7\n",
      "9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.576275\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.597626\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.617326\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623973\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.619492\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.615496\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625385\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.601302\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625159\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657390\n",
      "         Iterations 4\n",
      "10\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684408\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679391\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.672560\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682751\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681395\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684217\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689706\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678738\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683731\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683366\n",
      "         Iterations 4\n",
      "11\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.676585\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639616\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654720\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668121\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.671474\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.658382\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669127\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.665074\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.655949\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.645936\n",
      "         Iterations 5\n",
      "12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.394140\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.419652\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.374811\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.427549\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.381045\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.369966\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366605\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.371224\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.353142\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.387958\n",
      "         Iterations 7\n",
      "13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690734\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.644906\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.640212\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650673\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.665912\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.655931\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.647872\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650964\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.673573\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657099\n",
      "         Iterations 5\n",
      "14\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623243\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.655557\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.655490\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.640753\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.674629\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.647219\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.645814\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653577\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.645223\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.647649\n",
      "         Iterations 5\n",
      "15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.570942\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.429838\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514889\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.489576\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.505168\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.461700\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.498210\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516219\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509849\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.491080\n",
      "         Iterations 6\n",
      "16\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.664163\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.649929\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.613176\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.633968\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.613046\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608717\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.619023\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639726\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605619\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588290\n",
      "         Iterations 5\n",
      "17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.647222\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628485\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.615305\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.624642\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625320\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636954\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.624616\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.622732\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.618591\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652585\n",
      "         Iterations 5\n",
      "18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.665137\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668518\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656505\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648287\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652987\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.654089\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637105\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.629767\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.645078\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653201\n",
      "         Iterations 5\n",
      "19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.615761\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529684\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.530522\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589252\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.538062\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.528743\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537538\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532307\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.518521\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558548\n",
      "         Iterations 5\n",
      "20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.658753\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605890\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.552791\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.595827\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581745\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592650\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.593271\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566124\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.590581\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580684\n",
      "         Iterations 5\n",
      "21\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.621424\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.646913\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.629258\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.624061\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.635556\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.635085\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639238\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.627982\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639344\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.642534\n",
      "         Iterations 5\n",
      "22\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.565676\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540106\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563889\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.537026\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529376\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542555\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.524158\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.557235\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.530330\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.541901\n",
      "         Iterations 6\n",
      "23\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.630857\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.634894\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650799\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.644093\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.629297\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651842\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636154\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.640148\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670827\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625320\n",
      "         Iterations 5\n",
      "24\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636898\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607856\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608654\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.597591\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.604297\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.561789\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591363\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.601636\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608056\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.606628\n",
      "         Iterations 5\n",
      "25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683844\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657149\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650728\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.645277\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623939\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639351\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.621430\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.641448\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.611104\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625598\n",
      "         Iterations 5\n",
      "26\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497131\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.545943\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.545218\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553889\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.524740\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573523\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546612\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.551743\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.549548\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544513\n",
      "         Iterations 5\n",
      "27\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.424188\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.459746\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542264\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482889\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.520104\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.544174\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.454798\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.521096\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.545901\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.522669\n",
      "         Iterations 6\n",
      "28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677021\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650414\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639441\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608850\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.616235\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.615433\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.629841\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605810\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.640845\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.601999\n",
      "         Iterations 5\n",
      "29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650552\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605965\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.621719\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.610991\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.645496\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.627694\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.621679\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.626646\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.643732\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.643332\n",
      "         Iterations 5\n",
      "30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625377\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648885\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653466\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.664363\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670913\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682263\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657224\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.666986\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.646670\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653675\n",
      "         Iterations 5\n",
      "31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.634815\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668132\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.661094\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683991\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689899\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689074\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.673876\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679080\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653373\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.673728\n",
      "         Iterations 5\n",
      "32\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.645489\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.465592\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490200\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543232\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.552177\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.504609\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546706\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553892\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514485\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542624\n",
      "         Iterations 6\n",
      "33\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.462092\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.211242\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.194910\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.224731\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.206466\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.207819\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.191048\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.159587\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.161941\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.152019\n",
      "         Iterations 8\n",
      "34\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656392\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668521\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652664\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650122\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.641461\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.649792\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656843\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.641402\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.642111\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656815\n",
      "         Iterations 5\n",
      "35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.603555\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607471\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582477\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.590055\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.599378\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.567030\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.601079\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.571045\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579041\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592851\n",
      "         Iterations 5\n",
      "36\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683994\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.674188\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.660238\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651152\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.649812\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.655002\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.676805\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.669524\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657065\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.659835\n",
      "         Iterations 5\n",
      "37\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.675604\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.614760\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.619846\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.642042\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607773\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.624594\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.615342\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625714\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.633301\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.649376\n",
      "         Iterations 5\n",
      "38\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.425516\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.592460\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.622104\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623313\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.579576\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.594241\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605930\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582678\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.606196\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.597949\n",
      "         Iterations 5\n",
      "39\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.660424\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.638449\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602312\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.624117\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650971\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648565\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623343\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625288\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656608\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.641898\n",
      "         Iterations 5\n",
      "40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.689311\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607192\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.603736\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.568133\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.586767\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.621537\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.600162\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608459\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.597757\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574879\n",
      "         Iterations 5\n",
      "41\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681823\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.626924\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639792\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636856\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.647613\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637240\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.649321\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637054\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.627115\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.594395\n",
      "         Iterations 5\n",
      "42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682129\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639409\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636499\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.620145\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636993\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.604804\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.630961\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591123\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607755\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.630455\n",
      "         Iterations 5\n",
      "43\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.435842\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.344254\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.286680\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.265405\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.249308\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.248327\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.294752\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273491\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.264215\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.246104\n",
      "         Iterations 7\n",
      "44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.660915\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653210\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.635496\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.648756\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639795\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656411\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.635554\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.664587\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637822\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.631067\n",
      "         Iterations 5\n",
      "45\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.662291\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.621894\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.623910\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.612028\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.646494\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.616125\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.617111\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.626971\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625225\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.591117\n",
      "         Iterations 5\n",
      "46\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.386045\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274706\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274200\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.283898\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.296530\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273354\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.254550\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.235102\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.242738\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.245749\n",
      "         Iterations 7\n",
      "47\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681238\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.665049\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.635099\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.658346\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.662505\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.658686\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657726\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668108\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.674613\n",
      "         Iterations 4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.655155\n",
      "         Iterations 5\n",
      "48\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.551810\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.396377\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.460166\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.450504\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490921\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.438149\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.473224\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.474585\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.461161\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482013\n",
      "         Iterations 6\n",
      "49\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.576363\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.529574\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553516\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.505844\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.543099\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534544\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.526893\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516854\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.542324\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.508187\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "## establishing constants \n",
    "indiv = 500   ## number of individuals in study \n",
    "max_time = 10 ## number of time points being considered \n",
    "t_delay = 2 ## number of time delays included in model \n",
    "num_sims = 50 \n",
    "results = np.empty(num_sims)\n",
    "\n",
    "## RUNNING SIMULATIONS \n",
    "start_time = time.time() \n",
    "for ii in range(num_sims):\n",
    "    print(ii) \n",
    "    df = data_creation(indiv,max_time, 2, \"TRUE\") \n",
    "    Y_model = Y_model_creation(df, max_time)\n",
    "    L1_model_df = covariate_model_creation(df, max_time)\n",
    "    results[ii] = simulation_run(df, Y_model, L1_model_df, max_time, \"TRUE\")\n",
    "\n",
    "elapsed_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.hist(list(results[~np.isnan(results)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.133507746116\n",
      "0.00710806020948\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results))\n",
    "print(np.var(results)/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Results = pd.DataFrame(results)\n",
    "Results.to_csv(\"SIM_RESULTS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOUBLY ROBUST METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ logit[P(A_{m,i} = 1 \\mid \\bar{l}_{m,i}, \\bar{a}_{m-1,i}; \\alpha )] = w_m (\\bar{l}_{m,i}, \\bar{a}_{m-1,i}; \\alpha) $$ \n",
    "\n",
    "\n",
    "\n",
    "\"Correct\" model:\n",
    "$$logit(P[\\hat{A}_{m,i}]) = \\alpha_0 + \\alpha_1 \\cdot L_{m,i} + \\alpha_2 \\cdot A_{m-1,i} + \\alpha_3 \\cdot L_{m-1,i} + \\alpha_4 \\cdot L_{m-2,i} + \\alpha_5 \\cdot A_{m-2,i} + \\alpha_6 \\cdot A_{m-3,i}$$ \n",
    "\n",
    "\"Incorrect model\":\n",
    "$$logit(P[\\hat{A}_{m,i}]) = \\alpha_0 + \\alpha_1 \\cdot L_{m-3,i} + \\alpha_2 \\cdot A_{m-3,i}$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] pi_function creates the w_m function given the following:\n",
    "## the alpha model of A_{m,i}, the dataframe, the time (m), and an \n",
    "## indicator of whether this is the correct or incorrect model \n",
    "\n",
    "## do I need to do something in here like 1-expit for those A_j == 0?? \n",
    "## i.e. what I did in the last line here \n",
    "#########################################################################\n",
    "\n",
    "def pi_function(m, alpha_model, df, indiv, alpha_wrong): \n",
    "    product = [1]*indiv\n",
    "    for jj in range(2, m+1): \n",
    "        if alpha_wrong == \"FALSE\": \n",
    "            x = np.sum(alpha_model*np.array(sm.add_constant(df[df.time == jj][[\"L1\", \"A_1\", \\\n",
    "                \"L1_1\", \"L1_2\", \"A_2\"]])), axis = 1) \n",
    "        else: \n",
    "            x = np.sum(alpha_model*np.array(sm.add_constant(df[df.time == jj][[\"L1_3\", \"A_3\"]])), axis = 1)\n",
    "        product = product*sp.special.expit(x)\n",
    "    \n",
    "    x = np.array(np.divide([1]*indiv, product))\n",
    "    x[np.where(df[df.time == m][\"A_1\"] == 0.0)] = 1 - x[np.where(df[df.time == m][\"A_1\"] == 0.0)]\n",
    "    return(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] alpha_model_creation creates the logistic regression \n",
    "## for the observed treatment (A) data from the current and previous \n",
    "## covariates and the previous treatments (A) over all time periods and\n",
    "## individuals \n",
    "\n",
    "## -- need to create the functionality for multiple covariates\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "def alpha_model_creation(df, wrong): \n",
    "    alpha_df = pd.DataFrame(columns = [\"A\", \"l\", \"a_1\", \"l_1\", \"l_2\", \"l_3\", \"a_2\", \"a_3\"])\n",
    "     \n",
    "    for ii in range(1,len(df)): \n",
    "        if df.loc[ii][\"time\"] > 2.0:\n",
    "            alpha_df.loc[len(alpha_df)+1] = [df.loc[ii].A, df.loc[ii].L1, df.loc[ii][\"A_1\"], \\\n",
    "                                             df.loc[ii][\"L1_1\"], df.loc[ii][\"L1_2\"],  df.loc[ii][\"L1_3\"], \\\n",
    "                                             df.loc[ii][\"A_2\"], df.loc[ii][\"A_3\"]]\n",
    "\n",
    "    if wrong == \"TRUE\":\n",
    "        alpha_model = sm.Logit(np.asarray(alpha_df.A),np.asarray(sm.add_constant(alpha_df[[\"l_3\", \"a_3\"]]))).fit().params\n",
    "    else: \n",
    "        alpha_model = sm.Logit(np.asarray(alpha_df.A),np.asarray(sm.add_constant(alpha_df[[\"l\", \"a_1\", \"l_1\",\\\n",
    "                      \"l_2\", \"a_2\"]]))).fit().params\n",
    "    return(alpha_model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##[FUNCTION] DR_estimate_creation calculates the causal effect for a \n",
    "## given treatment of interest (test_value), including an indicator \n",
    "## of whether the correct or incorrect model is being used \n",
    "\n",
    "#########################################################################\n",
    "\n",
    "def DR_estimate_creation(test_value, max_time, df, indiv, wrong_model):\n",
    "    alpha_model = alpha_model_creation(df,wrong_model)\n",
    "    \n",
    "    A_test = [test_value]*indiv \n",
    "    model_df = pd.DataFrame(columns = [\"time\", \"beta_0\", \"beta_1\", \"beta_2\", \\\n",
    "                \"beta_3\", \"beta_4\", \"beta_5\", \"beta_6\", \"phi\"])\n",
    "    time.counter = max_time\n",
    "    T = list(df[df.time == max_time].Y)\n",
    "\n",
    "    while(time.counter > 2.0): \n",
    "        time_df = df.loc[df.time == time.counter]\n",
    "        time_df[\"T\"] = np.array(T)\n",
    "        pi = pi_function(time.counter, alpha_model, df, indiv, wrong_model) \n",
    "        time_df[\"pi\"] = pi \n",
    "        train_columns ='+'.join(map(str, np.append(list(time_df)[6:12], \\\n",
    "                        list(time_df)[13])))\n",
    "        time_df = time_df.astype(float)\n",
    "        S_model = smf.ols(\"T~\"+train_columns, data=time_df).fit()\n",
    "        model_df = model_df.append(pd.DataFrame([time.counter] + \\\n",
    "                   [S_model.params[i] for i in range(0,8)]).transpose(), ignore_index=True)\n",
    "        time_df[\"A_1\"] = np.array(A_test)\n",
    "        new_T = np.sum([S_model.params[i] for i in range(0,8)]*\\\n",
    "                np.array(sm.add_constant(time_df.loc[:,np.append(list(time_df)[6:12], \\\n",
    "                list(time_df)[13])], has_constant='add')), axis=1)\n",
    "        T = sp.special.expit(new_T)\n",
    "        time.counter = time.counter-1\n",
    "    \n",
    "    return(np.nanmean(T))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.570341\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.491204\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487255\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.502533\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496035\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.505612\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487435\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.489860\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.472231\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509489\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.491788\n",
      "         Iterations 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:21: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:22: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683707\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683707\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563820\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.513432\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.498012\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509849\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.522858\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.473487\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.475601\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.476730\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.520972\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500733\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.502387\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:21: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:22: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683277\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.683277\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573787\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509179\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.501638\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.487718\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490745\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.463192\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.479191\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.473661\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495298\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482227\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.470073\n",
      "         Iterations 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:21: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:22: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684444\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.684444\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.595912\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.517846\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.471329\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.479417\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.488121\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486653\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.491764\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495465\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.501917\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.503183\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.496270\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:21: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:22: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682615\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682615\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553485\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.528446\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.462136\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.509402\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.495586\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486505\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497313\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514074\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.506890\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.483361\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500568\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:21: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:22: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682557\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682557\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: str() < int(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n",
      "/Users/morganfbreitmeyer/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/indexes/api.py:71: RuntimeWarning: unorderable types: int() > str(), sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    }
   ],
   "source": [
    "## CONSTANTS \n",
    "alpha = np.random.uniform(low = -1.0, high = 1.0, size = 6)\n",
    "beta = np.random.uniform(low = -1.0, high = 1.0, size = 5)\n",
    "alpha[5] = alpha[5] + 1.5\n",
    "indiv = 1000 \n",
    "max_time = 11\n",
    "num_sims = 5\n",
    "results_g_formula = np.empty(num_sims)\n",
    "results_dr_estimator = np.empty(num_sims)\n",
    "\n",
    "for ii in range(0, num_sims): \n",
    "    print(ii) \n",
    "    \n",
    "    df = data_creation2(indiv, max_time, 1, \"TRUE\", alpha, beta) \n",
    "    Y_model = Y_model_creation(df, max_time)\n",
    "    L1_model_df = covariate_model_creation(df, max_time)\n",
    "    results_g_formula[ii] = simulation_run2(df, Y_model, L1_model_df, max_time, \"TRUE\", 1) - simulation_run2(df, Y_model, L1_model_df, max_time, \"TRUE\", 0)\n",
    "    \n",
    "    df = df.iloc[:,0:12]\n",
    "    results_dr_estimator[ii] = DR_estimate_creation(1.0, max_time, df, indiv, \"TRUE\")-\\\n",
    "    DR_estimate_creation(0.0, max_time, df, indiv, \"TRUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results_g_formula))\n",
    "print(np.var(results_g_formula/num_sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.06147067317e-05\n",
      "0.000338003249718\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results_dr_estimator))\n",
    "print(np.sqrt(np.var(results_dr_estimator)/num_sims)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_g_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
