%!TEX root = ../dissertation.tex
\chapter{Introduction}
\label{introduction}

\newthought{Causation versus association} -- the age-old debate rages on among statisticians, scientists, and students alike.  Association is easier to understand: are two or more things related to each other?  Do taller people weigh more than shorter people?  Is the temperature colder when there is snow on the ground than when there is not?  Do people who drink red wine and eat dark chocolate have healthier hearts? 

Proving association is simpler than causation.  Select a group of random, unrelated people who drink red wine and eat dark chocolate and a second group of random, unrelated people who do not, and compare their resting heart rates and HDL (``good'' cholesterol) levels.  If the red wine drinkers and chocolate consumers have better heart health, then it can be concluded that consuming red wine and dark chocolate is associated with a healthier heart.  But, there is a catch.  This exercise only demonstrates that consuming red wine and chocolate is correlated with a healthy heart; it does not prove that red wine and chocolate actually cause heart health.  Perhaps everyone who consumes red wine and dark chocolate also exercises more frequently, is of a healthier weight, or is younger than those who do not, all possible factors that could lead to a healthier heart separate from an individual's red wine and chocolate habits.  The association found between dark chocolate and red wine consumption could be reflective of these other healthy heart habits rather than an indication of red wine and dark chocolate driving heart health.  This exercise of association does not isolate the underlying cause of the difference between the two groups. 
 
This begs the question of causation; how can one actually prove that the red wine and the dark chocolate cause heart health?  Answering this question is not as simple as showing correlation, and, traditionally, a randomized trial is required.  A randomized trial experiment involves enrolling a sufficient number of patients, who are randomly assigned into one of two groups: those who are told to drink red wine and eat dark chocolate (the treatment group) and those who are told not to (the controls).  A trial like this would likely go on for some extended period of time, maybe years.  The individuals in both groups would have their heart rate and their HDL levels measured along the way.  Using this data, researchers could quantify the difference in outcome between the treatment and control groups to demonstrate an association between treatment and outcome.  The randomized nature of this trial is what allows researchers to conclude that the association between consuming red wine and dark chocolate and heart health is actually causation.\footnote{The idea behind this conclusion is discussed further in Chapter \ref{background}.} However, this process of the controlled randomized trial is complicated, costly, and, until recently, often unfeasible or unethical.  
 
Randomized controlled trials are commonly used in medicine to test the efficacy of a treatment drug.  In the US, it takes 12 years and an average of more than \$350 million to undergo drug testing and FDA approval.\cite{drugapproval}  FDA approval requires proof of statistically significant causation of the drug's efficacy through at least two randomized controlled trials.  The difficulty surrounding these trials makes the medical innovation process terribly slow, expensive, and inefficient, purely because the current means of proving causation are so challenging.  
 
Further complicating this process, a more complex randomized control trial exists in the form of the sequentially randomized trial.  In these trials, several points of randomization exist, leading to more groups than just the control and the treatment groups.  Even more, the random mechanism for assigning treatment or control can vary by group.  For instance, consider a trial studying ovarian cancer treatments, where researchers want to test the efficacy of several drugs on different stages of the cancer and want to use a more intense regimen for those with life threatening disease.  The researchers decide to only accept subjects whose cancer is in stage 1 or 2, and for those individuals at each time point, the decision to assign treatment or control is entirely random.  However, as the trial continues, some subjects' cancer progresses to stage 3 or 4, so the doctors want to increase the drug dosage.  Because the prognosis is more pressing at this point, the researchers may decide that it is important to switch treatments for those individuals.  For those subjects, researchers again randomly assign subjects to a different more aggressive treatment or to the same regimen.   By the design of the study, this reassignment must again be done randomly, but researchers could indicate that this switch in treatment is a priority, influencing the likelihood that the random assignment results in a treatment change.  At each checkup, the researchers perform several tests, such as cancer size, metastatic progression, and morbidity, and using this information, they reassess whether an individual should be switched from the less aggressive treatment group to the more aggressive treatment group. Based off of that additional information, subjects are again assigned a treatment regimen.  This progression of reassessment and random reassignment continues throughout the trial at various time checkpoints.  Sequentially randomized trials can be even more sophisticated with numerous treatment types and dispensation strategies.\cite{doi:10.1093/jnci/djm185}  

A sequentially randomized trial such as this one intends to provide a more nuanced understanding of a treatment's efficacy.  However, this comes at the cost of being quite complicated analytically; conclusions are difficult to define.  No longer can researchers perform a simple test on an outcome measure between the control and treatment groups.  Instead, with many more and varied treatments over time, the procedures and analysis become even more complicated.  While still expensive and time consuming, isolating a causal effect is no longer a simple calculation.  
 
In the last few decades, an alternative solution to these analytical problems has emerged in a field of statistics known as causal inference.  It creates and studies various methods to establish causation by means other than the traditional randomized trial.  This field emphasizes methods that can work strictly from observational data, or data that contains more sophisticated frameworks.  Some examples of observational data include hospital data accumulated over millions of patients and years that track symptoms, level types, outcomes, and demographic surveys, as well as data from other experimental trials.  Deploying these alternative methods could decrease the cost and time for proving causation in drug trials, thereby impacting millions of lives.  

This thesis is a comparative examination of two distinct methods of causal inference: the g-formula and the doubly robust estimator.  Both methods utilize observational data to establish rigorous measures of causation without the traditional mechanisms of randomized trials.  They also have the capacity to prove causal effects within dynamic treatment regimens, such as those seen in the sequentially randomized trial, an improvement not seen in former methods of causal inference.  The doubly robust estimator is an improved development of the g-formula and is shown to be much more effective at correctly approximating causal effect.  It will be shown that this method can withstand significant error caused by human inaccuracy in model selection, resulting in a more consistently precise estimator.  

In order to draw causal conclusions using these methods, certain requirements for the context of the data must be fulfilled.  If these assumptions are satisfied, these methods can be used on either sequentially randomized trials such as the one for ovarian cancer discussed above or observational data.  For instance, there must be at least a sufficient, albeit small, number of individuals given each possible treatment pathway.  Furthermore, group assignment methods, however complex, must be randomized such that no single group is more or less exposed to exogenous survival factors such as age, gender, general health, or morbidity.  Moreover, the treatments given must be consistent and well regulated so that the results are clear -- for example, the possible pathways of treatment must be predetermined and not altered at the last minute.  Finally, the most difficult assumption to meet is that sufficient data exists in order to properly adjust for all common causes of the treatment and the outcome.  The methods use this information in order to isolate the causation from other influences.  In the study on red wine and chocolate drinking, these include factors such as subject weight, age, exercise habits, smoking, medical history, consumption history of red wine and chocolate, among many other possible factors.  This assumption is the most difficult to meet and impossible to guarantee.  
  
In short, with more efficiency, efficacy, and ease, these more advanced methods have widespread applicability in medicine, as novel discoveries arise out of years of underutilized data.  However, the validity of their results is contingent on a stringent set of assumptions being met.  If these conditions are satisfied, the potential impact is significant from the study of observational data in addition to the implications for the study of more sophisticated trial types.  Firstly, the cost savings are of unbelievable magnitude.  If causation can be established without years of clinical trials, both governments and research organizations will save millions of dollars.  Furthermore, a key agenda of the National Academy of Sciences and the Humane Society is to find suitable alternatives to animal testing for drug trials in the face of an inefficient medical system in the United States.\cite{dzauvital, avoidinganimaltesting}   This method provides the framework to replace or supplement many clinical trials, preventing some need for animal testing.  Secondly, the typical timeline of a clinical trial could be drastically decreased using these methods.  Observational data already dates back many years and causal results could be acquired in days rather than years, allowing for more efficient medical innovation at a significantly more rapid pace.  Thirdly, this method has never before been implemented in Python or in a parallelized fashion, so it can now be applied to very large data sets and in a significantly more efficient manner.  The popular idea of big data applies here, with ever-growing databases of medical history data and little methodology in place to process it.  Previous to this, performing such calculations using other statistical platforms would either take days to weeks or be computationally impossible. This new implementation could contribute to managing the ever-growing databases of medical history data, which currently have little methodology in place to process them efficiently.  All of these innovations could revolutionize the study of modern medicine; nevertheless, parameters for this method, as discussed above, must be rigorously applied in order to effectively establish causal effects.  In total, while this thesis applies causal inference methods specifically to the framework of medicine and clinical trials, these methods have powerful external applicability. They can be applied to many other fields, including the social sciences, hard sciences, and economics.  



